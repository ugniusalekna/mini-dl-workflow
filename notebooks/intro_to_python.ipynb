{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Introduction to Python and PyTorch\n",
    "===================================\n",
    "This is a quick intro to Python programming and PyTorch -- the very basics.\n",
    "You'll get a feel for simple Python concepts like:\n",
    "- Variables and simple math\n",
    "- Lists, dictionaries, and loops\n",
    "- Functions and lambda expressions\n",
    "- Classes, objects, and inheritance (with dunder methods)\n",
    "- Using iterators with built-in functions like range(), iter(), and next()\n",
    "\n",
    "Helpful Resources:\n",
    "- Python Documentation: https://docs.python.org/3/\n",
    "- PyTorch Documentation: https://pytorch.org/docs/stable/index.html\n",
    "\n",
    "TODO: Follow through the sections and run the provided examples.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 1. Introduction to Python Basics\n",
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 10\n",
      "b = 3.14\n",
      "c = Hello!\n",
      "d = True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----- Python Variables and Data Types -----\n",
    "a = 10        # an integer\n",
    "b = 3.14      # a float\n",
    "c = \"Hello!\"  # a string\n",
    "d = True      # aboolean\n",
    "\n",
    "print(\"a =\", a)\n",
    "print(\"b =\", b)\n",
    "print(\"c =\", c)\n",
    "print(\"d =\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Alice and I am 25 years old.\n",
      "Pi rounded to 2 decimals: 3.14\n",
      "Sum of a and b: 13.14\n"
     ]
    }
   ],
   "source": [
    "# ----- f-Strings for Easy Formatting -----\n",
    "name = \"Alice\"\n",
    "age = 25\n",
    "print(f\"My name is {name} and I am {age} years old.\")\n",
    "pi = 3.14159\n",
    "print(f\"Pi rounded to 2 decimals: {pi:.2f}\")\n",
    "print(f\"Sum of a and b: {a + b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My list: [1, 2, 3, 4, 5]\n",
      "First three items: [1, 2, 3]\n",
      "Last two items: [4, 5]\n",
      "Every second item: [1, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# ----- Lists, Slicing, and Dictionaries -----\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "print(\"My list:\", my_list)\n",
    "print(\"First three items:\", my_list[:3])\n",
    "print(\"Last two items:\", my_list[-2:])\n",
    "print(\"Every second item:\", my_list[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary 'name': Alice\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\n",
    "    0: \"Alice\", \n",
    "    1: 25,\n",
    "}\n",
    "print(\"Dictionary 'name':\", my_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping with range():\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# ----- Loops, Iterators, and Built-ins -----\n",
    "print(\"Looping with range():\")\n",
    "for i in range(5):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Manual iteration using iter() and next():\")\n",
    "it = iter(my_list)\n",
    "print(next(it))\n",
    "print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For loop over list (iterator in action):\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(\"For loop over list (iterator in action):\")\n",
    "for item in my_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 + 4 = 7\n",
      "3 * 4 = 12\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 2. Functions and Lambda Expressions\n",
    "# -----------------------------------\n",
    "\"\"\"\n",
    "Functions let you reuse code.\n",
    "Lambda functions give you a short way to write simple functions.\n",
    "\"\"\"\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "print(\"3 + 4 =\", add(3, 4))\n",
    "\n",
    "multiply = lambda x, y: x * y\n",
    "print(\"3 * 4 =\", multiply(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3. Python Classes, Dunder Methods, and Inheritance\n",
    "# ---------------------------------------------------\n",
    "\"\"\"\n",
    "Classes are blueprints for creating objects.\n",
    "They can have:\n",
    "  - __init__: for initializing new objects;\n",
    "  - __str__: for a nice string representation;\n",
    "  - __call__: to let objects be callable like functions;\n",
    "  - __len__: to let objects have a definition of length;\n",
    "  - ... and many others.\n",
    "We'll also see how inheritance lets you build on existing classes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 10, 15, 20]\n",
      "Calling container(3): [3, 6, 9, 12]\n",
      "Length of container: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- Basic Class Example -----\n",
    "class MyClass:\n",
    "    def __init__(self, items):\n",
    "        \"\"\"\n",
    "        Initialize the container with a list of items.\n",
    "        \"\"\"\n",
    "        self.items = items\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Return a string representation of the container.\n",
    "        \"\"\"\n",
    "        return f\"MyContainer holding: {self.items}\"\n",
    "\n",
    "    def __call__(self, multiplier):\n",
    "        \"\"\"\n",
    "        When called, return a new list with each item multiplied by the given value.\n",
    "        \"\"\"\n",
    "        return [item * multiplier for item in self.items]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of items in the container.\n",
    "        \"\"\"\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.items[idx]\n",
    "\n",
    "\n",
    "container = MyClass([1, 2, 3, 4])\n",
    "print(container(5))# Uses __str__\n",
    "print(\"Calling container(3):\", container(3))    # Uses __call__\n",
    "print(\"Length of container:\", len(container))   # Uses __len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Inheritance Example -----\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    def greet(self):\n",
    "        return f\"Hi, I'm {self.name}.\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name} is {self.age} years old\"\n",
    "\n",
    "\n",
    "class Student(Person):\n",
    "    def __init__(self, name, age, student_id):\n",
    "        super().__init__(name, age)\n",
    "        self.student_id = student_id\n",
    "\n",
    "    def greet(self):\n",
    "        return f\"{super().greet()} My student ID is {self.student_id}.\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}, {self.age} years old, ID: {self.student_id}\"\n",
    "\n",
    "\n",
    "student = Student(\"Bob\", 22, \"S12345\")\n",
    "print(student.greet())\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 4. Quick Mention of NumPy and Matplotlib\n",
    "# -------------------------------------------------\n",
    "\"\"\"\n",
    "NumPy is a core library for numerical computing in Python. It provides\n",
    "multidimensional arrays and a large collection of mathematical functions.\n",
    "\n",
    "Matplotlib is a plotting library that can help visualize data and model outputs.\n",
    "\n",
    "Below is a quick look at how to create a NumPy array, how to convert a PyTorch\n",
    "tensor to a NumPy array, and how to do a simple plot with Matplotlib.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ----- Basic NumPy Usage -----\n",
    "np_array = np.array([1, 2, 3, 4, 5])\n",
    "print(f\"NumPy array: {np_array}\")\n",
    "print(f\"Shape of np_array: {np_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise operations\n",
    "np_array_squared = np_array ** 2\n",
    "print(f\"Squared NumPy array: {np_array_squared}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Converting between PyTorch and NumPy -----\n",
    "tensor = torch.tensor([10, 20, 30])\n",
    "numpy_array = tensor.numpy()\n",
    "\n",
    "print(f\"\\nTorch tensor: {tensor}; type: {type(tensor)}\")\n",
    "print(f\"Converted to NumPy: {numpy_array}; type: {type(numpy_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Matplotlib Example -----\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's plot our np_array vs np_array_squared\n",
    "plt.figure()\n",
    "plt.plot(np_array, np_array_squared, marker='o', label='y = x^2')\n",
    "plt.title(\"Simple Plot Using Matplotlib\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 5. Introduction to PyTorch\n",
    "# --------------------------------\n",
    "\"\"\"\n",
    "PyTorch is a popular library for deep learning in Python.\n",
    "It's very similar to NumPy, except it also supports GPU acceleration,\n",
    "automatic differentiation (autograd), and other features that make\n",
    "building neural networks and training models more intuitive.\n",
    "\n",
    "Main Concepts:\n",
    "-------------\n",
    "1. Tensors:\n",
    "   - The core data structure in PyTorch (similar to NumPy arrays).\n",
    "   - Can be placed on CPU or GPU to leverage hardware acceleration.\n",
    "2. Operations:\n",
    "   - Math, slicing, broadcasting, reshaping, etc.\n",
    "3. Autograd:\n",
    "   - Automatically calculates gradients for backpropagation.\n",
    "4. Device Management:\n",
    "   - Easily move tensors between CPU and GPU devices.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ----- Checking for GPU (or Apple Metal Performance Shaders) Availability -----\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Creating Tensors -----\n",
    "# From Python lists\n",
    "tensor_a = torch.tensor([1, 2, 3])\n",
    "# Randomly initialized (3x2 and 2x3)\n",
    "tensor_b = torch.randn(3, 2)\n",
    "tensor_c = torch.randn(2, 3)\n",
    "# Using torch.arange (similar to range(), but for tensors)\n",
    "tensor_d = torch.arange(6).reshape(2, 3)\n",
    "\n",
    "print(f\"tensor_a: {tensor_a.shape}\\n{tensor_a}\")\n",
    "print(f\"tensor_b: {tensor_b.shape}\\n{tensor_b}\")\n",
    "print(f\"tensor_c: {tensor_c.shape}\\n{tensor_c}\")\n",
    "print(f\"tensor_d: {tensor_d.shape}\\n{tensor_d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move a tensor to GPU if available\n",
    "tensor_a = tensor_a.to(device)\n",
    "tensor_b = tensor_b.to(device)\n",
    "tensor_c = tensor_c.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Tensor Operations -----\n",
    "# Basic arithmetic\n",
    "sum_ab = tensor_a.float().sum()  # Summation\n",
    "mul_bc = tensor_b @ tensor_c    # Matrix multiplication (3x2 @ 2x3 = 3x3)\n",
    "\n",
    "# Element-wise operations\n",
    "sin_a = torch.sin(tensor_a.float())\n",
    "exp_b = torch.exp(tensor_b)\n",
    "\n",
    "print(f\"sum_ab (sum of tensor_a): {sum_ab.item()}\")\n",
    "print(f\"mul_bc (matrix multiplication b @ c^T):\\n{mul_bc}\")\n",
    "print(f\"sin_a (element-wise sine on tensor_a):{sin_a}\")\n",
    "print(f\"exp_b (element-wise exp on tensor_b):\\n{exp_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Indexing and Slicing -----\n",
    "# Let's create a new tensor for demonstration\n",
    "tensor_e = torch.arange(9, device=device).reshape(3, 3)\n",
    "print(f\"tensor_d:\\n{tensor_e}\")\n",
    "print(f\"First row of tensor_d: {tensor_e[0, :]}\")\n",
    "print(f\"Last column of tensor_d: {tensor_e[:, -1]}\")\n",
    "print(f\"Top-left 2x2 slice:\\n{tensor_e[:2, :2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Autograd: Automatic Differentiation Example -----\n",
    "# For demonstration, let's define a simple operation y = (x^2 + 2x + 1)\n",
    "x = torch.tensor([2.0], device=device, requires_grad=True)\n",
    "y = x**2 + 2*x + 1\n",
    "\n",
    "# Backprop to compute dy/dx\n",
    "y.backward()\n",
    "print(f\"Value of y when x=2: {y.item()}\")\n",
    "print(f\"Gradient dy/dx at x=2: {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demonstration of gradient accumulation in PyTorch, and why we usually\n",
    "need to zero out gradients in a training loop.\n",
    "\n",
    "1. We first show that if we keep calling backward() without resetting,\n",
    "   gradients will accumulate in x.grad.\n",
    "\n",
    "2. Then, we show the \"correct\" approachâ€”manually zeroing out the gradients\n",
    "   each iteration (or using an optimizer's built-in zero_grad() method).\n",
    "\"\"\"\n",
    "import torch\n",
    "device = 'mps'\n",
    "x = torch.tensor([2.0], device=device, requires_grad=True)\n",
    "\n",
    "print(\"---- Without zeroing out gradients ----\")\n",
    "for _ in range(1, 4):\n",
    "    # Define a simple function: y = 2 * x \n",
    "    y = 2 * x\n",
    "    # Backward pass: compute gradient dy/dx and accumulate in x.grad\n",
    "    y.backward()\n",
    "    print(f\"Iteration {i} -> y = {y.item()}, accumulated grad = {x.grad.item()}\")\n",
    "    # Notice the gradient in x.grad is growing each time.\n",
    "\n",
    "print(f\"Final accumulated gradient in x.grad after loop: {x.grad.item()}\\n\")\n",
    "\n",
    "# Reset (zero) the gradient before the next demonstration\n",
    "x.grad.zero_()\n",
    "\n",
    "print(\"---- With zeroing out gradients each iteration ----\")\n",
    "for _ in range(1, 4):\n",
    "    y = 2 * x\n",
    "    # Zero out the gradient from the previous iteration\n",
    "    x.grad.zero_()\n",
    "    y.backward()\n",
    "    print(f\"Iteration {i} -> y = {y.item()}, fresh grad = {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-----------\n",
    "- PyTorch accumulates gradients in the .grad attribute after every backward() call.\n",
    "- If we don't clear (zero) this attribute, it stacks up from multiple backward calls.\n",
    "- Typically in training:\n",
    "     1. optimizer.zero_grad()  # or param.grad.zero_() for each parameter\n",
    "     2. loss.backward()\n",
    "     3. optimizer.step()\n",
    "  This ensures each iteration calculates gradients fresh, rather than\n",
    "  adding them to old gradient values.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
